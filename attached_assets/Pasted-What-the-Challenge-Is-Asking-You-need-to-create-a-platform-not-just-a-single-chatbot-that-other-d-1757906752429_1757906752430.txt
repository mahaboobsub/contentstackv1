What the Challenge Is Asking

You need to create a platform (not just a single chatbot) that other developers can use to easily build their own custom chat agents.

Think of it as:
ğŸ‘‰ Instead of hardcoding one chatbot for one website, youâ€™re building a plug-and-play framework where devs can hook in Contentstack + LLMs (Groq, OpenAI, Anthropic) with just a few steps.

Two Core Deliverables
1. LLM Model API (Backend)

A server (e.g., FastAPI/Node.js) that:

Chat Streaming: Accepts chat messages and streams back LLM responses (token by token).

Multi-Provider Support: Can switch between Groq, OpenAI, Anthropic, etc.
(e.g., devs can set provider="Groq" in config).

Contentstack Integration: Uses MCP (Model Context Protocol) to fetch relevant content from Contentstack CMS.
Example: User asks â€œWhat tours are available for Italy?â€ â†’ Your API fetches â€œItaly Toursâ€ entries from Contentstack.

2. Chat SDK (Frontend Dev Kit)

A lightweight JavaScript/React SDK that:

Provides an easy-to-use useChat hook or ChatWidget component.

Lets developers drop a chat agent into any site/app with 1â€“2 lines of code.

Automatically connects to your LLM Model API.

âš¡ Example:

import { ChatWidget } from "contentiq-chat-sdk";

<ChatWidget apiUrl="https://yourapi.com/chat" />

What Your Platform Should Handle Automatically

Understanding intent (turns â€œtours in Italy?â€ into a query to Contentstack CMS).

Fetching CMS content (through Delivery API via MCP).

Returning a natural response from the LLM (not just raw CMS data).

Minimal setup for developers (they donâ€™t need to know backend logic).

Contentstack Products You MUST Use

CMS â†’ Where the structured content (e.g., â€œToursâ€, â€œProductsâ€, â€œBlogsâ€) lives.
(You fetch entries from here to answer questions).

Launch â†’ Use it to host or embed your chat widget inside the Contentstack ecosystem.
(Judges want to see deployment through Launch, not just Replit/localhost).

MCP â†’ The official protocol for querying live content from Contentstack (instead of directly calling APIs).
(This makes your integration â€œofficialâ€ and modern).

Developer Hub (OAuth) â†’ Register your app here to securely access Contentstack APIs with stack-level credentials.
(This shows youâ€™re using Contentstackâ€™s full developer workflow).

End Result (Example Demo)

Imagine a travel site using your platform:

Visitor asks: â€œWhat tours are available for Italy?â€

Your SDK â†’ sends query to API.

API â†’ LLM interprets â†’ fetches â€œItaly Toursâ€ from Contentstack (via MCP).

LLM crafts a nice response:
â€œHere are 3 tours in Italy: Rome City Tour, Venice Canals Experience, Tuscany Wine Trail. Would you like prices?â€

The dev didnâ€™t need to code any of this logic â€” your platform handled it.

âœ… In summary:
This PS is about building a developer-friendly toolkit (API + SDK) that makes it super easy to add an LLM-powered, CMS-aware chatbot to any site. The killer part is showing how Contentstack CMS + MCP + Launch + OAuth all fit together in your solution.